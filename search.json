[{"path":"index.html","id":"welcome","chapter":"1 Welcome!","heading":"1 Welcome!","text":"ideas can add welcome page? Open issue pull request.","code":""},{"path":"community-contribution.html","id":"community-contribution","chapter":"2 Community Contribution","heading":"2 Community Contribution","text":"fairly open-ended assignment provides opportunity receive credit contributing collective learning class, perhaps beyond. reflect minimum 3 hours work. complete assignment must submit short description contribution. appropriate, attach relevant files.many ways can contribute:organize lead workshop particular topic (date may assignment due date need schedule )help students find final project partnersgive well-rehearsed 5 minute lightning talk class datavis topic (theory tool) (email set date – may assignment due date need schedule )create video tutorial (length)create cheatsheet resourcewrite tutorial tool ’s well documentedbuild viz product (ex. htmlwidget RStudio add-) class use[idea](Note: translations allowed)may draw expand existing resources. , critical cite sources.","code":""},{"path":"community-contribution.html","id":"important-logistics","chapter":"2 Community Contribution","heading":"2.1 IMPORTANT LOGISTICS","text":"","code":""},{"path":"community-contribution.html","id":"groups","chapter":"2 Community Contribution","heading":"2.1.1 Groups","text":"may work partner choosing. work alone, need join group 1, simply submit work CourseWorks solo assignment.work partner, add group CC page People tab. Ed Discussion can used find partners similar interests.","code":""},{"path":"community-contribution.html","id":"what-to-submit","chapter":"2 Community Contribution","heading":"2.1.2 What to submit","text":"cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)","code":""},{"path":"community-contribution.html","id":"submitting-your-assignment","chapter":"2 Community Contribution","heading":"2.1.3 Submitting your assignment","text":"must submit assignment twice: CourseWorks (can graded) class, details follow.CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .Class (GitHub) submission: detail provided separate assignment.Class (GitHub) submission: detail provided separate assignment.","code":""},{"path":"community-contribution.html","id":"grading","chapter":"2 Community Contribution","heading":"2.1.4 Grading","text":"graded quality work, originality, effort invested. sources used must cited.","code":""},{"path":"github-submission-instructions.html","id":"github-submission-instructions","chapter":"3 GitHub submission instructions","heading":"3 GitHub submission instructions","text":"chapter gives information need upload community contribution. Please read entire document carefully making submission. particular note fact bookdown requires different .Rmd format ’re used , must make changes beginning file described submitting.","code":""},{"path":"github-submission-instructions.html","id":"background","chapter":"3 GitHub submission instructions","heading":"3.1 Background","text":"web site makes use bookdown package render collection .Rmd files nicely formatted online book chapters subchapters. job submit slightly modified version community contribution .Rmd file GitHub repository source files web site stored. backend, admins divide chapters book sections order .community contribution different format, create short .Rmd file explains , includes links relevant files, slides, etc. can post GitHub repo (another online site.)","code":""},{"path":"github-submission-instructions.html","id":"preparing-your-.rmd-file","chapter":"3 GitHub submission instructions","heading":"3.2 Preparing your .Rmd file","text":"submit ONE Rmd file.completing modifications, .Rmd look like sample .Rmd.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.second line blank, followed name(s):\n# Base R vs. ggplot2\n\nAaron Burr Alexander Hamilton\n\ncontent starts . second line blank, followed name(s):project requires data, please use built-dataset read directly URL, :\ndf <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.project requires data, please use built-dataset read directly URL, :df <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:\n{r, include=FALSE}\ninstead :\n{r setup, include=FALSE}included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:instead :project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:\n\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must installed sourceIf project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:developed .Rmd file moving library() statements rest file content, highly recommended knit review document . may change namespace available section code development, causing function work exhibit unexpected behavior.file contain getwd() / setwd() calls (never use scripts anyway!) write statements.Want get fancy? See optional tweaks section .","code":"# Base R vs. ggplot2\n\nAaron Burr and Alexander Hamilton\n\nYour content starts here. {r, include=FALSE}{r setup, include=FALSE}\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must be installed from source"},{"path":"github-submission-instructions.html","id":"submission-steps","chapter":"3 GitHub submission instructions","heading":"3.3 Submission steps","text":"submit work, following “Workflow #4” – submitting pull request someone else’s repository write access. Instructions available lecture slides topic well tutorial. repeated abbreviated form, specific instructions naming conventions, content information, important details.Fork cc21fall1 repo (repo) GitHub account.Fork cc21fall1 repo (repo) GitHub account.Clone/download forked repo local computer.Clone/download forked repo local computer.Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:\n![Test Photo](resources/sample_project/pumpkins.jpg)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:![Test Photo](resources/sample_project/pumpkins.jpg)ready submit project, push branch remote repo. Follow tutorial create pull request.ready submit project, push branch remote repo. Follow tutorial create pull request.point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.","code":""},{"path":"github-submission-instructions.html","id":"optional-tweaks","chapter":"3 GitHub submission instructions","heading":"3.4 Optional tweaks","text":"prefer links chapter open new tabs, add {target=\"_blank\"} link, :\n[edav.info](edav.info){target=\"_blank\"}prefer links chapter open new tabs, add {target=\"_blank\"} link, :[edav.info](edav.info){target=\"_blank\"}Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.","code":""},{"path":"github-submission-instructions.html","id":"faq","chapter":"3 GitHub submission instructions","heading":"3.5 FAQ","text":"","code":""},{"path":"github-submission-instructions.html","id":"what-should-i-expect-after-creating-a-pull-request","chapter":"3 GitHub submission instructions","heading":"3.5.1 What should I expect after creating a pull request?","text":"Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.take time can process pull requests, long see pull request repo, don’t worry.take time can process pull requests, long see pull request repo, don’t worry.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-before-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.2 What if I catch mistakes before my pull request is merged?","text":"Just make changes branch, commit push GitHub. automatically added pull request.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-after-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.3 What if I catch mistakes after my pull request is merged?","text":"may submit additional pull requests fix material site. edits small, fixing typos, easiest make edits directly GitHub, following instructions. merge first pull requests edits, please patient.","code":""},{"path":"github-submission-instructions.html","id":"other-questions","chapter":"3 GitHub submission instructions","heading":"3.5.4 Other questions","text":"additional questions, please ask Discussions section respond.Thank contributions!","code":""},{"path":"sample-project.html","id":"sample-project","chapter":"4 Sample project","heading":"4 Sample project","text":"Joe Biden Donald TrumpThis chapter gives sample layout Rmd file.Test Photo","code":""},{"path":"r-vs.-python-visualization-cheatsheet.html","id":"r-vs.-python-visualization-cheatsheet","chapter":"5 R vs. Python Visualization Cheatsheet","heading":"5 R vs. Python Visualization Cheatsheet","text":"Dawei Minhui LiaoWe found primarily work R data visualization may familiar graphs Python. lot differences R Python, usually use ggplot2 R, closest comparable libraries Matplotlib Seaborn working Python. Therefore, made PDF version cheat sheet people primarily use R Python need use one another programming language make plots, easily compare difference graphs.Click following link check cheat sheet:https://github.com/Aaralyn-Liao/EDAV_Contribution_CC8/blob/main/r_vs_python_visualization.pdf","code":""},{"path":"rpackage-waffle-cheatsheet.html","id":"rpackage-waffle-cheatsheet","chapter":"6 Rpackage waffle cheatsheet","heading":"6 Rpackage waffle cheatsheet","text":"Yibo ChenThis project mainly include pdf version cheatsheet R package waffle.Take look cheatsheet using link :\nhttps://github.com/ChenYb9807/cu_edav_cc/blob/main/Community%20Contribution.pdf","code":""},{"path":"multithreading-crawler-frame.html","id":"multithreading-crawler-frame","chapter":"7 multithreading crawler frame","heading":"7 multithreading crawler frame","text":"Yi YangAll work uploaded Github, ’s url:https://github.com/yiyangnju/multithreading-crawler-frame","code":""},{"path":"regression-and-classification-in-r.html","id":"regression-and-classification-in-r","chapter":"8 Regression and Classification in R","heading":"8 Regression and Classification in R","text":"Parv JoshiThis video tutorial, can found https://youtu./J2rnDy9PB3E. code created part video given contents file, reference. links used data set:Data.csvData.csvTitanic.csvTitanic.csvAmes_Housing_data.csvAmes_Housing_data.csvBoxcox Implementation R - 1Boxcox Implementation R - 1Boxcox Implementation R - 2Boxcox Implementation R - 2Peanalized RegressionPeanalized RegressionStepwise Selection MethodStepwise Selection MethodAccuracy MetricsAccuracy MetricsRmd CheatsheetRmd Cheatsheet","code":""},{"path":"regression-and-classification-in-r.html","id":"libraries-and-warnings","chapter":"8 Regression and Classification in R","heading":"8.0.1 Libraries and Warnings","text":"","code":"\n# Removing messages and warnings from knited version\nknitr::opts_chunk$set(warning = FALSE, message = FALSE)\n\n# Libraries\n# Make sure these are installed before running them. They all are a part of CRAN.\n\nlibrary(RCurl)\nlibrary(tidyverse)\nlibrary(randomForest)\nlibrary(caTools)\nlibrary(car)\nlibrary(MASS)\nlibrary(leaps)\nlibrary(caret)\nlibrary(bestglm)\nlibrary(rpart)\nlibrary(rattle)"},{"path":"regression-and-classification-in-r.html","id":"reading-data","chapter":"8 Regression and Classification in R","heading":"8.0.2 Reading Data","text":"","code":"\n# Importing the dataset\n\ndataset = read.csv(\"https://raw.githubusercontent.com/Parv-Joshi/EDAV_CC_Datasets/main/Data.csv\")\n\n# str(dataset)\n# View(dataset)"},{"path":"regression-and-classification-in-r.html","id":"data-preprocessing","chapter":"8 Regression and Classification in R","heading":"8.0.3 Data Preprocessing","text":"","code":"\n# Mean Imputation for Missing Data\ndataset$Age = ifelse(is.na(dataset$Age),\n                     ave(dataset$Age, FUN = function(x) mean(x, na.rm = T)),\n                     dataset$Age)\n\ndataset$Salary = ifelse(is.na(dataset$Salary),\n                        ave(dataset$Salary, FUN = function(x) mean(x, na.rm = T)),\n                        dataset$Salary)\n\n# Encoding Categorical Variables\ndataset$Country = factor(dataset$Country, \n                         labels = c(\"France\", \"Spain\", \"Germany\"), \n                         levels = c(\"France\", \"Spain\", \"Germany\"))\ndataset$Purchased = factor(dataset$Purchased, \n                           levels = c(\"Yes\", \"No\"), \n                           labels = c(1, 0))\n\n# Splitting Data into Training and Testing\n\nset.seed(123)\n\nsplit = sample.split(dataset$Purchased, SplitRatio = 0.8)\ntraining_set = subset(dataset, split == T)\ntest_set = subset(dataset, split == F)\n\n# Feature Scaling\ntraining_set[, 2:3] = scale(training_set[, 2:3])\ntest_set[, 2:3] = scale(test_set[, 2:3])"},{"path":"regression-and-classification-in-r.html","id":"regression","chapter":"8 Regression and Classification in R","heading":"8.0.4 Regression","text":"","code":"\n# Data \n\ndata(\"Salaries\", package = \"carData\")\n# force(Salaries)\n\nattach(Salaries)\ndetach(Salaries)\n\n# str(Salaries)\n# View(Salaries)\n\n# Simple Variable Regression\n\nmodel = lm(Salaries$salary ~ Salaries$yrs.since.phd)\nmodel = lm(salary ~ yrs.since.phd, data = Salaries)\n\nmodel## \n## Call:\n## lm(formula = salary ~ yrs.since.phd, data = Salaries)\n## \n## Coefficients:\n##   (Intercept)  yrs.since.phd  \n##       91718.7          985.3\nsummary(model)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -84171 -19432  -2858  16086 102383 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    91718.7     2765.8  33.162   <2e-16 ***\n## yrs.since.phd    985.3      107.4   9.177   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27530 on 395 degrees of freedom\n## Multiple R-squared:  0.1758, Adjusted R-squared:  0.1737 \n## F-statistic: 84.23 on 1 and 395 DF,  p-value: < 2.2e-16\nstargazer::stargazer(model, type = \"text\")## \n## ===============================================\n##                         Dependent variable:    \n##                     ---------------------------\n##                               salary           \n## -----------------------------------------------\n## yrs.since.phd               985.342***         \n##                              (107.365)         \n##                                                \n## Constant                   91,718.680***       \n##                             (2,765.792)        \n##                                                \n## -----------------------------------------------\n## Observations                    397            \n## R2                             0.176           \n## Adjusted R2                    0.174           \n## Residual Std. Error    27,533.580 (df = 395)   \n## F Statistic           84.226*** (df = 1; 395)  \n## ===============================================\n## Note:               *p<0.1; **p<0.05; ***p<0.01\n# Multiple Variable Regression\n\nmodel1 = lm(salary ~ yrs.since.phd + yrs.service, data = Salaries)\nsummary(model1)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -79735 -19823  -2617  15149 106149 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    89912.2     2843.6  31.620  < 2e-16 ***\n## yrs.since.phd   1562.9      256.8   6.086 2.75e-09 ***\n## yrs.service     -629.1      254.5  -2.472   0.0138 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27360 on 394 degrees of freedom\n## Multiple R-squared:  0.1883, Adjusted R-squared:  0.1842 \n## F-statistic: 45.71 on 2 and 394 DF,  p-value: < 2.2e-16\n### Model:\n### salary = 89912.2 + 1562.9 * yrs.since.phd + (-629.1) * yrs.service\n\n\n# Categorical Variables\n\ncontrasts(Salaries$sex)##        Male\n## Female    0\n## Male      1\n# sex = relevel(sex, ref = \"Male\")\n\nmodel2 = lm(salary ~ yrs.since.phd + yrs.service + sex, data = Salaries)\nsummary(model2)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + yrs.service + sex, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -79586 -19564  -3018  15071 105898 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    82875.9     4800.6  17.264  < 2e-16 ***\n## yrs.since.phd   1552.8      256.1   6.062 3.15e-09 ***\n## yrs.service     -649.8      254.0  -2.558   0.0109 *  \n## sexMale         8457.1     4656.1   1.816   0.0701 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27280 on 393 degrees of freedom\n## Multiple R-squared:  0.1951, Adjusted R-squared:  0.189 \n## F-statistic: 31.75 on 3 and 393 DF,  p-value: < 2.2e-16\ncar::Anova(model2)## Anova Table (Type II tests)\n## \n## Response: salary\n##                   Sum Sq  Df F value   Pr(>F)    \n## yrs.since.phd 2.7346e+10   1 36.7512 3.15e-09 ***\n## yrs.service   4.8697e+09   1  6.5447  0.01089 *  \n## sex           2.4547e+09   1  3.2990  0.07008 .  \n## Residuals     2.9242e+11 393                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nmodel3 = lm(salary ~ ., data = Salaries)\ncar::Anova(model3)## Anova Table (Type II tests)\n## \n## Response: salary\n##                   Sum Sq  Df F value    Pr(>F)    \n## rank          6.9508e+10   2 68.4143 < 2.2e-16 ***\n## discipline    1.9237e+10   1 37.8695 1.878e-09 ***\n## yrs.since.phd 2.5041e+09   1  4.9293   0.02698 *  \n## yrs.service   2.7100e+09   1  5.3348   0.02143 *  \n## sex           7.8068e+08   1  1.5368   0.21584    \n## Residuals     1.9812e+11 390                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(model3)## \n## Call:\n## lm(formula = salary ~ ., data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -65248 -13211  -1775  10384  99592 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    65955.2     4588.6  14.374  < 2e-16 ***\n## rankAssocProf  12907.6     4145.3   3.114  0.00198 ** \n## rankProf       45066.0     4237.5  10.635  < 2e-16 ***\n## disciplineB    14417.6     2342.9   6.154 1.88e-09 ***\n## yrs.since.phd    535.1      241.0   2.220  0.02698 *  \n## yrs.service     -489.5      211.9  -2.310  0.02143 *  \n## sexMale         4783.5     3858.7   1.240  0.21584    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 22540 on 390 degrees of freedom\n## Multiple R-squared:  0.4547, Adjusted R-squared:  0.4463 \n## F-statistic:  54.2 on 6 and 390 DF,  p-value: < 2.2e-16\n# Transformations and Interaction Terms\n\nmodel4 = lm(salary ~ yrs.since.phd^2 + yrs.service, data = Salaries)\nsummary(model4)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd^2 + yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -79735 -19823  -2617  15149 106149 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    89912.2     2843.6  31.620  < 2e-16 ***\n## yrs.since.phd   1562.9      256.8   6.086 2.75e-09 ***\n## yrs.service     -629.1      254.5  -2.472   0.0138 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27360 on 394 degrees of freedom\n## Multiple R-squared:  0.1883, Adjusted R-squared:  0.1842 \n## F-statistic: 45.71 on 2 and 394 DF,  p-value: < 2.2e-16\nmodel4 = lm(salary ~ yrs.since.phd + I(yrs.since.phd^2) + yrs.service, data = Salaries)\nsummary(model4)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + I(yrs.since.phd^2) + yrs.service, \n##     data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -63538 -18063  -1946  14919 105025 \n## \n## Coefficients:\n##                     Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)        64971.002   3950.746  16.445  < 2e-16 ***\n## yrs.since.phd       4222.493    394.237  10.711  < 2e-16 ***\n## I(yrs.since.phd^2)   -62.321      7.389  -8.434 6.42e-16 ***\n## yrs.service         -234.596    239.075  -0.981    0.327    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 25210 on 393 degrees of freedom\n## Multiple R-squared:  0.3127, Adjusted R-squared:  0.3075 \n## F-statistic: 59.61 on 3 and 393 DF,  p-value: < 2.2e-16\nmodel4 = lm(salary ~ yrs.since.phd + I(yrs.since.phd^2) + I(yrs.since.phd^3) + yrs.service, data = Salaries)\nsummary(model4)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + I(yrs.since.phd^2) + I(yrs.since.phd^3) + \n##     yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -63538 -18062  -1947  14917 105023 \n## \n## Coefficients:\n##                      Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)         6.498e+04  5.559e+03  11.688  < 2e-16 ***\n## yrs.since.phd       4.221e+03  8.990e+02   4.696 3.68e-06 ***\n## I(yrs.since.phd^2) -6.227e+01  3.877e+01  -1.606    0.109    \n## I(yrs.since.phd^3) -6.720e-04  4.935e-01  -0.001    0.999    \n## yrs.service        -2.346e+02  2.395e+02  -0.979    0.328    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 25240 on 392 degrees of freedom\n## Multiple R-squared:  0.3127, Adjusted R-squared:  0.3057 \n## F-statistic:  44.6 on 4 and 392 DF,  p-value: < 2.2e-16\nmodel4 = lm(I(log(salary)) ~ yrs.since.phd + I(yrs.since.phd^2) + I(yrs.since.phd^3) + yrs.service, data = Salaries)\nsummary(model4)## \n## Call:\n## lm(formula = I(log(salary)) ~ yrs.since.phd + I(yrs.since.phd^2) + \n##     I(yrs.since.phd^3) + yrs.service, data = Salaries)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.68247 -0.15590 -0.00244  0.14242  0.74830 \n## \n## Coefficients:\n##                      Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)         1.115e+01  4.617e-02 241.467  < 2e-16 ***\n## yrs.since.phd       4.073e-02  7.467e-03   5.454 8.72e-08 ***\n## I(yrs.since.phd^2) -6.626e-04  3.220e-04  -2.058   0.0403 *  \n## I(yrs.since.phd^3)  6.168e-07  4.099e-06   0.150   0.8805    \n## yrs.service        -1.433e-03  1.989e-03  -0.720   0.4718    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.2096 on 392 degrees of freedom\n## Multiple R-squared:  0.3575, Adjusted R-squared:  0.3509 \n## F-statistic: 54.52 on 4 and 392 DF,  p-value: < 2.2e-16\nmodel5 = lm(salary ~ yrs.since.phd:yrs.service, data = Salaries)\nsummary(model5)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd:yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -80936 -21633  -3841  17621 106895 \n## \n## Coefficients:\n##                            Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)               1.071e+05  1.983e+03  53.982  < 2e-16 ***\n## yrs.since.phd:yrs.service 1.218e+01  2.431e+00   5.009 8.26e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 29410 on 395 degrees of freedom\n## Multiple R-squared:  0.05973,    Adjusted R-squared:  0.05735 \n## F-statistic: 25.09 on 1 and 395 DF,  p-value: 8.263e-07\n#### Boxcox\n\nsal = Salaries[, c(3,4,6)]\nshapiro.test(Salaries$salary)## \n##  Shapiro-Wilk normality test\n## \n## data:  Salaries$salary\n## W = 0.95988, p-value = 6.076e-09\n# Null: Data is normally distributed\n# p-value = 6.076e-09 < 0.05, reject null -> NOT Normal.\n\nmodel1 = lm(salary ~ yrs.since.phd + yrs.service, data = Salaries)\nsummary(model1)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -79735 -19823  -2617  15149 106149 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    89912.2     2843.6  31.620  < 2e-16 ***\n## yrs.since.phd   1562.9      256.8   6.086 2.75e-09 ***\n## yrs.service     -629.1      254.5  -2.472   0.0138 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27360 on 394 degrees of freedom\n## Multiple R-squared:  0.1883, Adjusted R-squared:  0.1842 \n## F-statistic: 45.71 on 2 and 394 DF,  p-value: < 2.2e-16\nbc = boxcox(model1)\nbest.lam = bc$x[which(bc$y == max(bc$y))]\nbest.lam## [1] -0.2222222\nmodel6 = lm(I(salary^best.lam) ~ yrs.since.phd + yrs.service, data = Salaries)\nsummary(model6)## \n## Call:\n## lm(formula = I(salary^best.lam) ~ yrs.since.phd + yrs.service, \n##     data = Salaries)\n## \n## Residuals:\n##        Min         1Q     Median         3Q        Max \n## -0.0099656 -0.0027195 -0.0000644  0.0028614  0.0150252 \n## \n## Coefficients:\n##                 Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    7.942e-02  4.095e-04 193.953  < 2e-16 ***\n## yrs.since.phd -2.260e-04  3.698e-05  -6.110 2.39e-09 ***\n## yrs.service    8.892e-05  3.665e-05   2.426   0.0157 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.00394 on 394 degrees of freedom\n## Multiple R-squared:  0.1929, Adjusted R-squared:  0.1888 \n## F-statistic: 47.09 on 2 and 394 DF,  p-value: < 2.2e-16\n### Adj. R^2 increased\n\n# Predictions using Training and Testing data\n\nset.seed(123)\nsplit = sample.split(Salaries$salary, SplitRatio = 0.8)\ntraining_set = subset(Salaries, split == T)\ntest_set = subset(Salaries, split == F)\n\nmodel7 = lm(salary ~ ., data = training_set)\ny_pred = predict(model7, test_set)\n# y_pred\ndata.frame(y_pred, test_set$salary)##        y_pred test_set.salary\n## 2   133991.08          173200\n## 4   138905.04          115000\n## 5   134650.37          141500\n## 8   135930.61          147765\n## 11  100457.55          119800\n## 16  135214.59          117150\n## 20  116504.49          137000\n## 21  121107.75           89565\n## 24  120009.45          113068\n## 31  139939.95          132261\n## 32   89375.54           79916\n## 34   87417.62           80225\n## 50   85955.45           70768\n## 53   86623.38           74692\n## 59   98656.53          100135\n## 65   86921.88           68404\n## 67  137279.32          101000\n## 68  136344.57           99418\n## 69  126670.46          111512\n## 84   88722.90           88825\n## 87  134675.41          152708\n## 88   86112.35           88400\n## 89  132792.62          172272\n## 104 130115.59          127512\n## 106 120116.27          113543\n## 107  84699.94           82099\n## 111 118886.12          112429\n## 114 119570.45          104279\n## 118 121371.46          117515\n## 126 124716.43           78162\n## 132 122055.79           76840\n## 137 117267.04          108262\n## 139  84543.04           73877\n## 145 133106.42          112696\n## 151 132058.21          128148\n## 173 141120.02           93164\n## 179 139551.03          147349\n## 181 130596.04          142467\n## 189 100984.98          106300\n## 190 135767.06          153750\n## 193 132346.97          122100\n## 195 101644.27           90000\n## 202 135146.11          119700\n## 206 141584.07           96545\n## 219  97391.59          109650\n## 220 131901.31          119500\n## 222 138923.43          145200\n## 230 120379.98          133900\n## 238  67420.64           63100\n## 240 123190.87           96200\n## 248 118547.28          101100\n## 249 120637.05          128800\n## 260 119777.43           92550\n## 261  91885.61           88600\n## 262 120825.64          107550\n## 264 118629.05          126000\n## 271 121346.42          143250\n## 277 123906.89          107200\n## 294  88170.11          104800\n## 296 122024.10           97150\n## 297 116589.36          126300\n## 300  91521.73           70700\n## 316  88227.16           84716\n## 317  95094.83           71065\n## 320 131876.27          135027\n## 321 133131.46          104428\n## 327 136444.74          124714\n## 330 132478.83          134778\n## 334 140988.16          145098\n## 340 145581.67          137317\n## 347 142243.36          142023\n## 352 134832.31           93519\n## 356 134775.58          145028\n## 360  75889.64           78785\n## 363 118472.15          138771\n## 373 118126.66          109707\n## 376 119149.83          103649\n## 380  84699.94          104121\n## 386 119093.10          114330\n## 391 130451.66          166605\n# Variable Selection\n\n# data\ndata(\"swiss\")\nattach(swiss)\n\n# ?swiss\n\n# Best Subsets regression\n\nmodels = leaps::regsubsets(Fertility ~ ., data = swiss, nvmax = 5)\nsummary(models)## Subset selection object\n## Call: regsubsets.formula(Fertility ~ ., data = swiss, nvmax = 5)\n## 5 Variables  (and intercept)\n##                  Forced in Forced out\n## Agriculture          FALSE      FALSE\n## Examination          FALSE      FALSE\n## Education            FALSE      FALSE\n## Catholic             FALSE      FALSE\n## Infant.Mortality     FALSE      FALSE\n## 1 subsets of each size up to 5\n## Selection Algorithm: exhaustive\n##          Agriculture Examination Education Catholic Infant.Mortality\n## 1  ( 1 ) \" \"         \" \"         \"*\"       \" \"      \" \"             \n## 2  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \" \"             \n## 3  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \"*\"             \n## 4  ( 1 ) \"*\"         \" \"         \"*\"       \"*\"      \"*\"             \n## 5  ( 1 ) \"*\"         \"*\"         \"*\"       \"*\"      \"*\"\n### Therefore, \n### Best 1-variable model: Fertility ~ Education\n### Best 2-variables model: Fertility ~ Education + Catholic\n### Best 3-variables model: Fertility ~ Education + Catholic + Infant.Mortality\n### Best 4-variables model: Fertility ~ Agriculture + Education + Catholic + Infant.Mortality\n### Best 5-variables model: Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality\n\nmodels.summary = summary(models)\ndata.frame(Adj.R2 = which.max(models.summary$adjr2),\n           CP = which.min(models.summary$cp),\n           BIC = which.min(models.summary$bic))##   Adj.R2 CP BIC\n## 1      5  4   4\n### Fertility ~ Agriculture + Education + Catholic + Infant.Mortality\n\n# Stepwise Variable Selection\nfit = lm(Fertility ~ ., data = swiss)\nstep = MASS::stepAIC(fit, direction = \"both\", trace = F) # change both to forward and backward\nstep## \n## Call:\n## lm(formula = Fertility ~ Agriculture + Education + Catholic + \n##     Infant.Mortality, data = swiss)\n## \n## Coefficients:\n##      (Intercept)       Agriculture         Education          Catholic  \n##          62.1013           -0.1546           -0.9803            0.1247  \n## Infant.Mortality  \n##           1.0784\ndetach(swiss)\n\n\n# Penalized Regression\n\names = read.csv(\"https://raw.githubusercontent.com/Parv-Joshi/EDAV_CC_Datasets/main/Ames_Housing_Data.csv\")\n# str(ames)\nanyNA(ames)## [1] FALSE\nset.seed(123)\ntraining.samples = createDataPartition(ames$SalePrice, p = 0.75, list = FALSE)\n\ntrain.data = ames[training.samples,]\ntest.data = ames[-training.samples,]\n\nlambda = 10^seq(-3, 3, length = 100)\n\n# Ridge Regression\nset.seed(123)\nridge = train(SalePrice ~ ., data = train.data, method = \"glmnet\",\n  trControl = trainControl(\"cv\", number = 10),\n  tuneGrid = expand.grid(alpha = 0, lambda = lambda))\n\n# LASSO\nset.seed(123)\nlasso = train(SalePrice ~ ., data = train.data, method = \"glmnet\",\n  trControl = trainControl(\"cv\", number = 10),\n  tuneGrid = expand.grid(alpha = 1, lambda = lambda))\n\n# Elastic Net\nset.seed(123)\nelastic = train(SalePrice ~ ., data = train.data, method = \"glmnet\",\n  trControl = trainControl(\"cv\", number = 10),\n  tuneLength = 10)\n\n# Comparison\nmodels = list(ridge = ridge, lasso = lasso, elastic = elastic)\nresamples(models) %>% summary(metric = \"RMSE\")## \n## Call:\n## summary.resamples(object = ., metric = \"RMSE\")\n## \n## Models: ridge, lasso, elastic \n## Number of resamples: 10 \n## \n## RMSE \n##             Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\n## ridge   24044.91 29603.57 30799.80 32919.29 37210.80 45150.33    0\n## lasso   23614.27 29604.97 31077.67 32800.93 37787.06 44271.58    0\n## elastic 23725.92 29688.82 31124.32 32770.19 37752.31 44115.51    0\n# Since Elastic model has the lowest mean RMSE, we can conclude that the Elastic model is the best."},{"path":"regression-and-classification-in-r.html","id":"classification","chapter":"8 Regression and Classification in R","heading":"8.0.5 Classification","text":"","code":"\n# Data\n\ndata(\"PimaIndiansDiabetes2\", package = \"mlbench\")\n\n# str(PimaIndiansDiabetes2)\n# View(PimaIndiansDiabetes2)\n\nPimaIndiansDiabetes2$diabetes = as.factor(PimaIndiansDiabetes2$diabetes)\nPimaIndiansDiabetes2 = na.omit(PimaIndiansDiabetes2)\n\nattach(PimaIndiansDiabetes2)\n\n# Training and Testing\n\nset.seed(123)\n\ntraining.samples = createDataPartition(diabetes, p = 0.8, list = FALSE)\n\ntrain.data = PimaIndiansDiabetes2[training.samples,]\ntest.data = PimaIndiansDiabetes2[-training.samples,]\n\n# Logistic Regression\n\nmodel = glm(diabetes ~ ., data = train.data, family = binomial)\nsummary(model)## \n## Call:\n## glm(formula = diabetes ~ ., family = binomial, data = train.data)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -2.5832  -0.6544  -0.3292   0.6248   2.5968  \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) -1.053e+01  1.440e+00  -7.317 2.54e-13 ***\n## pregnant     1.005e-01  6.127e-02   1.640  0.10092    \n## glucose      3.710e-02  6.486e-03   5.719 1.07e-08 ***\n## pressure    -3.876e-04  1.383e-02  -0.028  0.97764    \n## triceps      1.418e-02  1.998e-02   0.710  0.47800    \n## insulin      5.940e-04  1.508e-03   0.394  0.69371    \n## mass         7.997e-02  3.180e-02   2.515  0.01190 *  \n## pedigree     1.329e+00  4.823e-01   2.756  0.00585 ** \n## age          2.718e-02  2.020e-02   1.346  0.17840    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 398.80  on 313  degrees of freedom\n## Residual deviance: 267.18  on 305  degrees of freedom\n## AIC: 285.18\n## \n## Number of Fisher Scoring iterations: 5\nprobabilities = predict(model, test.data, type = \"response\")\nprobabilities##          19          21          32          55          64          71 \n## 0.192628377 0.485262263 0.662527248 0.798681474 0.278073391 0.145877334 \n##          72          74          98          99         108         111 \n## 0.314265178 0.232071188 0.007697533 0.066394837 0.357546947 0.552586956 \n##         115         128         154         182         215         216 \n## 0.715548197 0.132717063 0.706670106 0.189297618 0.291196167 0.911862874 \n##         224         229         260         293         297         313 \n## 0.704569592 0.993419157 0.932506403 0.721153294 0.328274489 0.293808296 \n##         316         326         357         369         376         385 \n## 0.120862955 0.201559764 0.390156419 0.022075579 0.885924184 0.075765425 \n##         386         393         394         410         429         447 \n## 0.042383376 0.102435789 0.095664525 0.885380718 0.379195274 0.053098974 \n##         450         453         468         470         477         487 \n## 0.091641699 0.097155564 0.122327231 0.831420989 0.216021458 0.525840641 \n##         541         542         546         552         555         556 \n## 0.461122260 0.270914264 0.890122464 0.066719675 0.068520682 0.197336318 \n##         562         563         564         577         589         592 \n## 0.894087110 0.075000107 0.091244654 0.163897301 0.912857186 0.200938223 \n##         595         600         609         610         621         634 \n## 0.491041316 0.048192839 0.549602575 0.034910473 0.203922043 0.081878938 \n##         666         673         674         681         683         694 \n## 0.133609108 0.100033198 0.782544310 0.007547670 0.145787456 0.629221735 \n##         697         699         710         716         717         719 \n## 0.485455842 0.290737653 0.141965217 0.925604098 0.839268863 0.161190610 \n##         722         731         733         734         746         766 \n## 0.168129887 0.191170873 0.852375783 0.078840151 0.305248512 0.125461309\ncontrasts(diabetes)##     pos\n## neg   0\n## pos   1\npredicted.classes = ifelse(probabilities > 0.5, \"pos\", \"neg\")\npredicted.classes##    19    21    32    55    64    71    72    74    98    99   108   111   115 \n## \"neg\" \"neg\" \"pos\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \"pos\" \"pos\" \n##   128   154   182   215   216   224   229   260   293   297   313   316   326 \n## \"neg\" \"pos\" \"neg\" \"neg\" \"pos\" \"pos\" \"pos\" \"pos\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \n##   357   369   376   385   386   393   394   410   429   447   450   453   468 \n## \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \n##   470   477   487   541   542   546   552   555   556   562   563   564   577 \n## \"pos\" \"neg\" \"pos\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \n##   589   592   595   600   609   610   621   634   666   673   674   681   683 \n## \"pos\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \n##   694   697   699   710   716   717   719   722   731   733   734   746   766 \n## \"pos\" \"neg\" \"neg\" \"neg\" \"pos\" \"pos\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\"\ncaret::confusionMatrix(factor(predicted.classes),\n                factor(test.data$diabetes),\n                positive = \"pos\")## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction neg pos\n##        neg  44  11\n##        pos   8  15\n##                                          \n##                Accuracy : 0.7564         \n##                  95% CI : (0.646, 0.8465)\n##     No Information Rate : 0.6667         \n##     P-Value [Acc > NIR] : 0.05651        \n##                                          \n##                   Kappa : 0.4356         \n##                                          \n##  Mcnemar's Test P-Value : 0.64636        \n##                                          \n##             Sensitivity : 0.5769         \n##             Specificity : 0.8462         \n##          Pos Pred Value : 0.6522         \n##          Neg Pred Value : 0.8000         \n##              Prevalence : 0.3333         \n##          Detection Rate : 0.1923         \n##    Detection Prevalence : 0.2949         \n##       Balanced Accuracy : 0.7115         \n##                                          \n##        'Positive' Class : pos            \n## \n# Stepwise regression\n\nstep = MASS::stepAIC(model, direction = \"both\", k = log(nrow(PimaIndiansDiabetes2)), trace = FALSE)\nstep$anova## Stepwise Model Path \n## Analysis of Deviance Table\n## \n## Initial Model:\n## diabetes ~ pregnant + glucose + pressure + triceps + insulin + \n##     mass + pedigree + age\n## \n## Final Model:\n## diabetes ~ pregnant + glucose + mass + pedigree\n## \n## \n##         Step Df     Deviance Resid. Df Resid. Dev      AIC\n## 1                                  305   267.1825 320.9239\n## 2 - pressure  1 0.0007857024       306   267.1833 314.9534\n## 3  - insulin  1 0.1591672501       307   267.3425 309.1413\n## 4  - triceps  1 0.4434205054       308   267.7859 303.6135\n## 5      - age  1 2.4276790188       309   270.2136 300.0699\n# Best subset regression\n\ncv_data = model.matrix( ~ ., PimaIndiansDiabetes2)[,-1]\ncv_data = data.frame(cv_data)\nbest = bestglm(cv_data, IC = \"BIC\", family = binomial)\nbest## BIC\n## BICq equivalent for q in (0.359009418385306, 0.859446547266463)\n## Best Model:\n##                 Estimate  Std. Error   z value     Pr(>|z|)\n## (Intercept) -10.09201799 1.080251137 -9.342289 9.427384e-21\n## glucose       0.03618899 0.004981946  7.264026 3.757357e-13\n## mass          0.07444854 0.020266697  3.673442 2.393046e-04\n## pedigree      1.08712862 0.419408437  2.592052 9.540525e-03\n## age           0.05301206 0.013439480  3.944502 7.996582e-05\ndetach(PimaIndiansDiabetes2)\n\n# Decision Tree Classification\n\ndata = read.csv(\"https://raw.githubusercontent.com/Parv-Joshi/EDAV_CC_Datasets/main/Titanic.csv\")\nattach(data)\n\n# str(data)\n\n# Excluding Variables\ndata = subset(data, select = -c(Name, Ticket, Cabin))\n\n# Removing Missing Data\ndata = subset(data, !is.na(Age))\n\n# Testing and Training set\n\nset.seed(123)\ntraining.samples = data$Survived %>% \n  createDataPartition(p = 0.8, list = FALSE)\n\ntrain.data = data[training.samples,]\ntest.data = data[-training.samples,]\n\n# Factoring Survived\ntrain.data$Survived = as.factor(train.data$Survived)\ntest.data$Survived = as.factor(test.data$Survived)\n\n# Decision Trees\nmodel = rpart::rpart(Survived ~ ., data = train.data, control = rpart.control(cp = 0))\nrattle::fancyRpartPlot(model, cex = 0.5)\nset.seed(123)\ntrain.data$Survived = as.factor(train.data$Survived)\nmodel2 = train(Survived ~ ., \n               data = train.data, \n               method = \"rpart\", \n               trControl = trainControl(\"cv\", number = 10), \n               tuneLength = 100)\n\nfancyRpartPlot(model2$finalModel, cex = 0.6)\nprobabilities = predict(model2, newdata = test.data)\n# we don't need to do  contrasts since Survived is already given in o and 1.\npredicted.classes = ifelse(probabilities == 1, \"1\", \"0\")\n\ncaret::confusionMatrix(factor(predicted.classes),\n                factor(test.data$Survived),\n                positive = \"1\")## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction  0  1\n##          0 74 19\n##          1  5 44\n##                                          \n##                Accuracy : 0.831          \n##                  95% CI : (0.759, 0.8886)\n##     No Information Rate : 0.5563         \n##     P-Value [Acc > NIR] : 3.722e-12      \n##                                          \n##                   Kappa : 0.6497         \n##                                          \n##  Mcnemar's Test P-Value : 0.007963       \n##                                          \n##             Sensitivity : 0.6984         \n##             Specificity : 0.9367         \n##          Pos Pred Value : 0.8980         \n##          Neg Pred Value : 0.7957         \n##              Prevalence : 0.4437         \n##          Detection Rate : 0.3099         \n##    Detection Prevalence : 0.3451         \n##       Balanced Accuracy : 0.8176         \n##                                          \n##        'Positive' Class : 1              \n## \n# Random Forest\n\nset.seed(123)\nmodel3 = train(Survived ~ ., \n              data = train.data, \n              method = \"rf\",\n              trControl = trainControl(\"cv\", number = 10),\n              importance = TRUE)\n\nprobabilities = predict(model3, newdata = test.data)\npredicted.classes = ifelse(probabilities == 1, \"1\", \"0\")\ncaret::confusionMatrix(factor(predicted.classes),\n                factor(test.data$Survived),\n                positive = \"1\")## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction  0  1\n##          0 76 21\n##          1  3 42\n##                                          \n##                Accuracy : 0.831          \n##                  95% CI : (0.759, 0.8886)\n##     No Information Rate : 0.5563         \n##     P-Value [Acc > NIR] : 3.722e-12      \n##                                          \n##                   Kappa : 0.6474         \n##                                          \n##  Mcnemar's Test P-Value : 0.0005202      \n##                                          \n##             Sensitivity : 0.6667         \n##             Specificity : 0.9620         \n##          Pos Pred Value : 0.9333         \n##          Neg Pred Value : 0.7835         \n##              Prevalence : 0.4437         \n##          Detection Rate : 0.2958         \n##    Detection Prevalence : 0.3169         \n##       Balanced Accuracy : 0.8143         \n##                                          \n##        'Positive' Class : 1              \n## \nrandomForest::varImpPlot(model3$finalModel, type = 1) # MeanDecreaseAccuracy\ncaret::varImp(model3, type = 1)## rf variable importance\n## \n##             Overall\n## Sexmale     100.000\n## Pclass       54.019\n## Fare         38.444\n## Age          37.316\n## SibSp        24.658\n## Parch        19.187\n## EmbarkedQ     4.655\n## EmbarkedS     3.630\n## EmbarkedC     3.560\n## PassengerId   0.000\nrandomForest::varImpPlot(model3$finalModel, type = 2) # MeanDecreaseGini\ncaret::varImp(model3, type = 2)## rf variable importance\n## \n##             Overall\n## Sexmale     100.000\n## Fare         62.753\n## Age          54.613\n## PassengerId  48.686\n## Pclass       35.447\n## SibSp        15.503\n## Parch        14.097\n## EmbarkedS     3.623\n## EmbarkedC     3.606\n## EmbarkedQ     0.000\ndetach(data)"},{"path":"tibble-vs.-dataframe.html","id":"tibble-vs.-dataframe","chapter":"9 Tibble vs. DataFrame","heading":"9 Tibble vs. DataFrame","text":"Jingfei Fang","code":"\nlibrary(tidyverse)\nlibrary(tibble)"},{"path":"tibble-vs.-dataframe.html","id":"introduction","chapter":"9 Tibble vs. DataFrame","heading":"9.0.1 Introduction","text":"tibble often considered neater format data frame, often used tidyverse ggplot2 packages. contains information data frame, manipulation representation tibbles different data frames aspects.","code":""},{"path":"tibble-vs.-dataframe.html","id":"getting-started-with-tibbles","chapter":"9 Tibble vs. DataFrame","heading":"9.0.2 1. Getting started with tibbles","text":"can tidyverse:can installing tibble package directly:","code":"\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n#install.packages(\"tibble\")\nlibrary(tibble)"},{"path":"tibble-vs.-dataframe.html","id":"creating-a-tibble","chapter":"9 Tibble vs. DataFrame","heading":"9.0.3 2. Creating a tibble","text":"can create tibble directly:can create tibble existing data frame using as_tibble(). use ‘iris’ dataset example:","code":"\ntib <- tibble(a = c(1,2,3), b = c(4,5,6), c = c(7,8,9))\ntib## # A tibble: 3 × 3\n##       a     b     c\n##   <dbl> <dbl> <dbl>\n## 1     1     4     7\n## 2     2     5     8\n## 3     3     6     9\ndf <- iris\nclass(df)## [1] \"data.frame\"\ntib <- as_tibble(df)\ntib## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # … with 140 more rows"},{"path":"tibble-vs.-dataframe.html","id":"unlike-data-frames-tibbles-dont-show-the-entire-dataset-when-you-print-it.","chapter":"9 Tibble vs. DataFrame","heading":"9.0.4 3. Unlike data frames, tibbles don’t show the entire dataset when you print it.","text":"","code":"\ntib## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # … with 140 more rows"},{"path":"tibble-vs.-dataframe.html","id":"tibbles-cannot-access-a-column-when-you-provide-a-partial-name-of-the-column-but-data-frames-can.","chapter":"9 Tibble vs. DataFrame","heading":"9.0.5 4. Tibbles cannot access a column when you provide a partial name of the column, but data frames can.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble","chapter":"9 Tibble vs. DataFrame","heading":"9.0.5.1 Tibble","text":"try match column name partial name, work.provide entire column name, work.","code":"\ntib <- tibble(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4))\ntib$st## NULL\ntib$str## [1] \"a\" \"b\" \"c\" \"d\""},{"path":"tibble-vs.-dataframe.html","id":"data-frame","chapter":"9 Tibble vs. DataFrame","heading":"9.0.5.2 Data Frame","text":"However, can access “str” column providing partial column name “st” (long partial name unique).","code":"\ndf <- data.frame(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4))\ndf$st## [1] \"a\" \"b\" \"c\" \"d\""},{"path":"tibble-vs.-dataframe.html","id":"when-you-access-only-one-column-of-a-tibble-it-will-keep-the-tibble-structure.-but-when-you-access-one-column-of-a-data-frame-it-will-become-a-vector.","chapter":"9 Tibble vs. DataFrame","heading":"9.0.6 5. When you access only one column of a tibble, it will keep the tibble structure. But when you access one column of a data frame, it will become a vector.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-1","chapter":"9 Tibble vs. DataFrame","heading":"9.0.6.1 Tibble","text":"Checking ’s still tibble:can see tibble structure preserved.","code":"\ntib[,\"str\"]## # A tibble: 4 × 1\n##   str  \n##   <chr>\n## 1 a    \n## 2 b    \n## 3 c    \n## 4 d\nis_tibble(tib[,\"str\"])## [1] TRUE"},{"path":"tibble-vs.-dataframe.html","id":"data-frame-1","chapter":"9 Tibble vs. DataFrame","heading":"9.0.6.2 Data Frame","text":"Checking ’s still data frame:’s longer data frame.","code":"\ndf[,\"str\"]## [1] \"a\" \"b\" \"c\" \"d\"\nis.data.frame(df[,\"str\"])## [1] FALSE"},{"path":"tibble-vs.-dataframe.html","id":"however-other-forms-of-subsetting-including-and-work-the-same-for-tibbles-and-data-frames.","chapter":"9 Tibble vs. DataFrame","heading":"9.0.6.3 However, other forms of subsetting, including [[ ]] and $, work the same for tibbles and data frames.","text":"can see subsetting [[ ]] $ also don’t preserve tibble structure.","code":"\ntib[[\"str\"]]## [1] \"a\" \"b\" \"c\" \"d\"\ndf[[\"str\"]]## [1] \"a\" \"b\" \"c\" \"d\"\ntib$str## [1] \"a\" \"b\" \"c\" \"d\"\ndf$str## [1] \"a\" \"b\" \"c\" \"d\""},{"path":"tibble-vs.-dataframe.html","id":"when-assigning-a-new-column-to-a-tibble-the-input-will-not-be-recycled-which-means-you-have-to-provide-an-input-of-the-same-length-of-the-other-columns.-but-a-data-frame-will-recycle-the-input.","chapter":"9 Tibble vs. DataFrame","heading":"9.0.7 6. When assigning a new column to a tibble, the input will not be recycled, which means you have to provide an input of the same length of the other columns. But a data frame will recycle the input.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-2","chapter":"9 Tibble vs. DataFrame","heading":"9.0.7.1 Tibble","text":"gives error tibble columns length 4, input (5,6) length 2 recycled.\nprovide input length:","code":"\ntib## # A tibble: 4 × 2\n##   str     int\n##   <chr> <dbl>\n## 1 a         1\n## 2 b         2\n## 3 c         3\n## 4 d         4\ntib$newcol <- c(5,6)## Error: Assigned data `c(5, 6)` must be compatible with existing data.\n## ✖ Existing data has 4 rows.\n## ✖ Assigned data has 2 rows.\n## ℹ Only vectors of size 1 are recycled.\ntib$newcol <- rep(c(5,6),2)\ntib## # A tibble: 4 × 3\n##   str     int newcol\n##   <chr> <dbl>  <dbl>\n## 1 a         1      5\n## 2 b         2      6\n## 3 c         3      5\n## 4 d         4      6"},{"path":"tibble-vs.-dataframe.html","id":"data-frame-2","chapter":"9 Tibble vs. DataFrame","heading":"9.0.7.2 Data Frame","text":"Data frames recycle input.","code":"\ndf##   str int\n## 1   a   1\n## 2   b   2\n## 3   c   3\n## 4   d   4\ndf$newcol <- c(5,6)\ndf##   str int newcol\n## 1   a   1      5\n## 2   b   2      6\n## 3   c   3      5\n## 4   d   4      6"},{"path":"tibble-vs.-dataframe.html","id":"reading-with-builtin-read.csv-function-will-output-data-frames-while-reading-with-read_csv-in-readr-package-inside-tidyverse-will-output-tibbles.","chapter":"9 Tibble vs. DataFrame","heading":"9.0.8 7. Reading with builtin read.csv() function will output data frames, while reading with read_csv() in “readr” package inside tidyverse will output tibbles.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"reading-csv-file-with-read.csv","chapter":"9 Tibble vs. DataFrame","heading":"9.0.8.1 Reading csv file with read.csv()","text":"","code":"\ndata <- read.csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")\nclass(data)## [1] \"data.frame\""},{"path":"tibble-vs.-dataframe.html","id":"reading-csv-file-with-read_csv","chapter":"9 Tibble vs. DataFrame","heading":"9.0.8.2 Reading csv file with read_csv()","text":"","code":"\ndata <- read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")\nclass(data)## [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\""},{"path":"tibble-vs.-dataframe.html","id":"tibbles-dont-support-support-arithmetic-operations-on-all-columns-well-the-result-will-be-converted-into-a-data-frame-without-any-notice.","chapter":"9 Tibble vs. DataFrame","heading":"9.0.9 8. Tibbles don’t support support arithmetic operations on all columns well, the result will be converted into a data frame without any notice.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-3","chapter":"9 Tibble vs. DataFrame","heading":"9.0.9.1 Tibble","text":"can see try multiply elements tibble 2, result correct turned data frame without notifications.","code":"\ntib <- tibble(a = c(1,2,3), b = c(4,5,6), c = c(7,8,9))\nclass(tib*2)## [1] \"data.frame\""},{"path":"tibble-vs.-dataframe.html","id":"data-frame-3","chapter":"9 Tibble vs. DataFrame","heading":"9.0.9.2 Data Frame","text":"data frames issue , converted type.","code":"\ndf <- data.frame(a = c(1,2,3), b = c(4,5,6), c = c(7,8,9))\nclass(df*2)## [1] \"data.frame\""},{"path":"tibble-vs.-dataframe.html","id":"tibbles-preserve-all-the-variable-types-while-data-frames-have-the-option-to-convert-string-into-factor.-in-older-versions-of-r-data-frames-will-convert-string-into-factor-by-default","chapter":"9 Tibble vs. DataFrame","heading":"9.0.10 9. Tibbles preserve all the variable types, while data frames have the option to convert string into factor. (In older versions of R, data frames will convert string into factor by default)","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-4","chapter":"9 Tibble vs. DataFrame","heading":"9.0.10.1 Tibble","text":"can see original data types variables preserved tibble.","code":"\ntib <- tibble(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4))\nstr(tib)## tibble [4 × 2] (S3: tbl_df/tbl/data.frame)\n##  $ str: chr [1:4] \"a\" \"b\" \"c\" \"d\"\n##  $ int: num [1:4] 1 2 3 4"},{"path":"tibble-vs.-dataframe.html","id":"data-frame-4","chapter":"9 Tibble vs. DataFrame","heading":"9.0.10.2 Data Frame","text":"use data frame, also preserve original types, “stringAsFactors = FALSE” default new versions R.However, also option convert string factor creating data frame setting “stringAsFactors = TRUE”.can see “str” column converted factor.","code":"\ndf <- data.frame(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4))\nstr(df)## 'data.frame':    4 obs. of  2 variables:\n##  $ str: chr  \"a\" \"b\" \"c\" \"d\"\n##  $ int: num  1 2 3 4\ndf <- data.frame(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4), stringsAsFactors = TRUE)\nclass(df$str)## [1] \"factor\""},{"path":"tibble-vs.-dataframe.html","id":"tibbles-work-well-with-ggplot2-just-like-data-frames.","chapter":"9 Tibble vs. DataFrame","heading":"9.0.11 10. Tibbles work well with ggplot2, just like data frames.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-5","chapter":"9 Tibble vs. DataFrame","heading":"9.0.11.1 Tibble:","text":"","code":"\nggplot(data = tib, mapping = aes(x=str, y=int)) +\n  geom_col(width = 0.3)"},{"path":"tibble-vs.-dataframe.html","id":"data-frame-5","chapter":"9 Tibble vs. DataFrame","heading":"9.0.11.2 Data Frame:","text":"","code":"\nggplot(data = df, mapping = aes(x=str, y=int)) +\n  geom_col(width = 0.3)"},{"path":"tibble-vs.-dataframe.html","id":"works-cited","chapter":"9 Tibble vs. DataFrame","heading":"9.1 Works Cited","text":"https://tibble.tidyverse.org/https://cran.r-project.org/web/packages/tibble/vignettes/tibble.htmlhttps://www.youtube.com/watch?v=_qHdqWx-vsQ&ab_channel=JoshuaFrench","code":""},{"path":"data-science-product-cycles-in-enterprises.html","id":"data-science-product-cycles-in-enterprises","chapter":"10 Data Science Product Cycles in Enterprises","heading":"10 Data Science Product Cycles in Enterprises","text":"Leo Du Hao LiAs Data Science students, typically work carefully prepared data problem sets professors designed lots effort guide students achieve learning objectives can mostly clearly measured within reasonable timeline. However, reality, almost never seamless achieve results. delivered Zoom talk Nov. 1st share unique perspectives different stages typical development life cycle Data Science powered products large enterprises, different teams involved, technologies often used, visualization tools techniques leveraged different stages.Due policies, share materials publicly. slide deck, well recording session available Courseworks submission, students taking EDAV Fall 2021 upon request.","code":""},{"path":"github-initial-setup.html","id":"github-initial-setup","chapter":"11 Github initial setup","heading":"11 Github initial setup","text":"Joyce Robbins","code":""},{"path":"github-initial-setup.html","id":"create-new-repo","chapter":"11 Github initial setup","heading":"11.1 Create new repo","text":"Create new repository copying template: http://www.github.com/jtr13/cctemplate following instructions README.","code":""},{"path":"github-initial-setup.html","id":"pages-in-repo-settings","chapter":"11 Github initial setup","heading":"11.2 Pages in repo settings","text":"Change source gh-pagesMay trigger GHA get work","code":""},{"path":"github-initial-setup.html","id":"add-packages-to-description-file","chapter":"11 Github initial setup","heading":"11.3 Add packages to DESCRIPTION file","text":"Need better process…Downloaded submissions CourseWorksCreate DESCRIPTION file. Add add dependencies projthis::proj_update_deps()https://twitter.com/ijlyttle/status/1370776366585614342Add Imports real DESCRIPTION file.Found problematic packages looking reverse dependencies packages failed install:devtools::revdep()Also used pak::pkg_deps_tree()Problems:magickrJava dependency qdap","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"tutorial-for-pull-request-mergers","chapter":"12 Tutorial for pull request mergers","heading":"12 Tutorial for pull request mergers","text":"","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"general","chapter":"12 Tutorial for pull request mergers","heading":"12.1 General","text":"following checklist steps perform merging pull request. point, ’re sure , request review one PR leaders.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-branch","chapter":"12 Tutorial for pull request mergers","heading":"12.2 Check branch","text":"PR submitted non-main branch.PR submitted main branch, provide instructions fix problem:Close PR.Close PR.Follow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesFollow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesIf trouble 2., delete local folder project, delete fork GitHub, start .trouble 2., delete local folder project, delete fork GitHub, start .Open new PR.Open new PR.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"examine-files-that-were-added-or-modified","chapter":"12 Tutorial for pull request mergers","heading":"12.3 Examine files that were added or modified","text":"ONE .Rmd file.ONE .Rmd file.additional resources resources/<project_name>/ folder.additional resources resources/<project_name>/ folder.files root directory besides .Rmd file.files root directory besides .Rmd file.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-filename","chapter":"12 Tutorial for pull request mergers","heading":"12.4 Check .Rmd filename","text":".Rmd filename words joined underscores, white space. (Update: need branch name.).Rmd filename can contain lowercase letters. (Otherwise filenames sort nicely repo home page.)","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-file-contents","chapter":"12 Tutorial for pull request mergers","heading":"12.5 Check .Rmd file contents","text":"file contain YAML header --- line.first line start single hashtag #, followed single whitespace, title.second line blank, followed author name(s).additional single hashtag headers chapter. (, new chapters created.)hashtag headers followed numbers since hashtags create numbered subheadings. Correct: ## Subheading. Incorrect: ## 3. Subheading.file contains setup chunk .Rmd file, contain setup label. (bookdown render fail duplicate chunk labels.)\n.e. use {r, include=FALSE} instead {r setup, include=FALSE}.\nSee sample .RmdLinks internal files must contain resources/<project_name>/ path, : ![Test Photo](resources/sample_project/election.jpg)file contain install.packages(), write functions, setwd(), getwd().’s anything else looks odd ’re sure, assign jtr13 review explain issue.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"request-changes","chapter":"12 Tutorial for pull request mergers","heading":"12.6 Request changes","text":"problems checks listed , explain pull request merged request changes following steps:, add changes requested label pull request.job pull request done now. contributors fix requests, review either move forward merge explain changes still need made.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"merge-the-pull-request","chapter":"12 Tutorial for pull request mergers","heading":"12.7 Merge the pull request","text":"good go, ’s time merge pull request. several steps.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"add-chapter-filename-to-_bookdown.yml-in-prs-branch","chapter":"12 Tutorial for pull request mergers","heading":"12.7.1 Add chapter filename to _bookdown.yml in PR’s branch","text":"access PR branch:Make sure PR branch checking PR branch name shown (main):Open _bookdown.yml file.Open _bookdown.yml file.delete everything file beginning rmd_files: [ add name new file single quotes followed comma:delete everything file beginning rmd_files: [ add name new file single quotes followed comma:? easier fix merge conflicts way. (better way merge main PR branch adding new file can’t done GitHub. ’s interest explain locally.)Save edited version.Save edited version.Click resolve conflicts button:Click resolve conflicts button:Cut new filename paste proper location. delete lines <<<<<<< xxxx, ======= >>>>>>>> main. short, file look correct ’re done. Click “Marked resolved” button green “Commit merge” button.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"pr-leaders-only-add-part-names-to-.rmd-for-every-first-article-in-part","chapter":"12 Tutorial for pull request mergers","heading":"12.7.2 PR Leaders only: Add part names to .Rmd for every first article in part","text":"adding first chapter PART.every first article part, add chapter name top .Rmd file, propose changes. example like .\n","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"merge-pr-and-leave-a-comment","chapter":"12 Tutorial for pull request mergers","heading":"12.7.3 Merge PR and leave a comment","text":"Now comes final step.develop experience confident things correctly, assign another PR merger review work:@aye21874 (Ayush), @clarissarjtai (Clarissa), @ejosied (Josie), @hwelinkim (Hyo Won), @ivanye2509 (Xin)\n@kfijan (Katharina), @ktsht (Alex), @mtz2110 (Maxwell), @s10singh97 (Shashwat), @ShiyuWang88 (Shiyu), @Shruti-Kaushal (Shruti), @verlocks (Zheyu)(Please fix names mistakes aren’t names go … don’t need submit pull request, just edit file commit main branch.)Go back conversation tab pull requests page, example:https://github.com/jtr13/cc20/pull/23#issuecomment-728506101Leave comments congratulations 🎉 (type :tada:) click green button merge.\n","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-updated-version","chapter":"12 Tutorial for pull request mergers","heading":"12.7.4 Check updated version","text":"successful merge means addition file files added project merge conflicts. mean book render deploy GitHub pages without issues. merge, take 5-10 minutes GitHub Actions render book deploy updated version. ’s problem notified email address . words, job done. However ’re interested, can check progress clicking Actions top repo.","code":""}]
